source("functions/data_tests.r")
test_stations_metadata(stations_metadata_df)
### 5: Final volume query:
source("gql-queries/vol_qry.r")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
install.packages("glue")
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
edges
edges <- vol_qry$data$trafficData$volume$byHour$edges
edges
# transform volumes
transform_volumes <- function(vol_qry) {
# Extracting the relevant data
edges <- vol_qry$data$trafficData$volume$byHour$edges
# Transforming to a dataframe
df <- data.frame(
from = sapply(edges, function(x) x$node$from),
to = sapply(edges, function(x) x$node$to),
volume = sapply(edges, function(x) x$node$total$volumeNumbers$volume)
)
# Convert to appropriate data types
df$from <- as.POSIXct(df$from, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$to <- as.POSIXct(df$to, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$volume <- as.numeric(df$volume)
return(df)
}
edges
transform_metadata_to_df <- function(df){
df[[1]] %>%
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = ""))  |>
mutate(latestData = as_datetime(latestData, tz = "UTC"))  |>
mutate(location = map(location, unlist)) |>
mutate(
lat = map_dbl(location, "latLon.lat"),
lon = map_dbl(location, "latLon.lon")
) %>%
select(-location)
}
# time function, task 4A
to_iso8601 <- function(datetime_variable, offset_days = 0){
datetime_variable <- as_datetime(datetime_variable)
offset_days <- days(x = offset_days)
datetime_variable <- datetime_variable + offset_days
result <- format(datetime_variable, "%Y-%m-%dT%H:%M:%SZ")
print(result)
}
to_iso8601("2016-09-04 10:11:11",-4) #testing
# transform volumes
transform_volumes <- function(vol_qry) {
# Extracting the relevant data
edges <- vol_qry$data$trafficData$volume$byHour$edges
# Transforming to a dataframe
df <- data.frame(
from = sapply(edges, function(x) x$node$from),
to = sapply(edges, function(x) x$node$to),
volume = sapply(edges, function(x) x$node$total$volumeNumbers$volume)
)
# Convert to appropriate data types
df$from <- as.POSIXct(df$from, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$to <- as.POSIXct(df$to, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$volume <- as.numeric(df$volume)
return(df)
}
edges <- vol_qry$data$trafficData$volume$byHour$edges
edges <- vol_qry$data$trafficData$volume$byHour$edges
# transform volumes
transform_volumes <- function(vol_qry) {
# Extracting the relevant data
edges <- vol_qry$data$trafficData$volume$byHour$edges
# Transforming to a dataframe
df <- data.frame(
from = sapply(edges, function(x) x$node$from),
to = sapply(edges, function(x) x$node$to),
volume = sapply(edges, function(x) x$node$total$volumeNumbers$volume)
)
# Convert to appropriate data types
df$from <- as.POSIXct(df$from, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$to <- as.POSIXct(df$to, format="%Y-%m-%dT%H:%M:%SZ", tz="UTC")
df$volume <- as.numeric(df$volume)
return(df)
}
# GQL for volumes, task 4b
vol_qry <- function(id, from, to) {
query <- glue('{
trafficData(trafficRegistrationPointId: <<id>>) {
volume {
byHour(from: <<from>>, to: <<to>>) {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}', .open = "<<", .close = ">>")
cat(query)
}
# testing
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
install.packages("glue")
library(glue)
install.packages("glue")
#install.packages("glue")
library(glue)
# GQL for volumes, task 4b
vol_qry <- function(id, from, to) {
query <- glue('{
trafficData(trafficRegistrationPointId: <<id>>) {
volume {
byHour(from: <<from>>, to: <<to>>) {
edges {
node {
from
to
total {
volumeNumbers {
volume
}
}
}
}
}
}
}
}', .open = "<<", .close = ">>")
cat(query)
}
# testing
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
transform_metadata_to_df <- function(df){
df[[1]] %>%
map(as_tibble) |>
list_rbind() |>
mutate(latestData = map_chr(latestData, 1, .default = ""))  |>
mutate(latestData = as_datetime(latestData, tz = "UTC"))  |>
mutate(location = map(location, unlist)) |>
mutate(
lat = map_dbl(location, "latLon.lat"),
lon = map_dbl(location, "latLon.lon")
) %>%
select(-location)
}
# time function, task 4A
to_iso8601 <- function(datetime_variable, offset_days = 0){
datetime_variable <- as_datetime(datetime_variable)
offset_days <- days(x = offset_days)
datetime_variable <- datetime_variable + offset_days
result <- format(datetime_variable, "%Y-%m-%dT%H:%M:%SZ")
print(result)
}
to_iso8601("2016-09-04 10:11:11",-4) #testing
source("functions/data_transformations.r")
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
# Let's try submitting the query:
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata %>% head()
#### 2: Transforming metadata
source("functions/data_transformations.r")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
#### 3: Testing metadata
source("functions/data_tests.r")
test_stations_metadata(stations_metadata_df)
### 5: Final volume query:
source("gql-queries/vol_qry.r")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
install.packages("glue")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
stations_metadata_df
# This file contains tests to be applied to
# the Vegvesen stations-data *after* being transformed
# to a data frame.
#
# All tests are packed in a function test_stations_metadata that apples
# all the aforementioned tests
# FIRST SECTION - Checking column names
test_stations_metadata_colnames <-
function(df) { # Creating a function which takes the df as an argument
# Inserting the expected column names of the df
expected_colnames <- c("id", "name", "latestData", "lat", "lon")
# If all the column names are equal to the expected column names
# then print PASS, if not the function prints FAIL
if (all(colnames(df) == expected_colnames) == TRUE) {
print("PASS: Data has the correct columns")
} else{
print("FAIL: Columns do not match the correct specification")
}
}
test_stations_metadata_colnames(stations_metadata_df) # Pass
# NEXT SECTION -
test_stations_metadata_nrows <-
function(df) { # Creating a function which takes df as argument
min_expected_rows <- 5000 #minimum expected rows of 5000
max_expected_rows <- 10000 #maximum expected rows of 10000
#logical test: if the number of rows are between the minimum expected and
# maximum expected rows, the dataset passes. If not, it fail.
if (nrow(df) > min_expected_rows & nrow(df) < max_expected_rows) {
print("PASS: Data has a reasonable number of rows")
} else if (nrow(df) <= min_expected_rows) {
print("FAIL: Data has suspiciously few rows")
} else {
print("FAIL: Data has suspiciously many rows")
}
}
test_stations_metadata_nrows(stations_metadata_df) # Testing; pass
# THIRD SECTION. Testing to see if the column types are chr, chr, dbl, dbl and dbl
# We do this by the function below
# if all the column types are equal to the expected, it passes. if not, fail
test_stations_metadata_coltypes <-
function(df) {
expected_coltypes <-
c("character", "character", "double", "double", "double")
if (all(df %>%
map_chr( ~ typeof(.)) == expected_coltypes) == TRUE) {
print("PASS: All cols have the correct specifications")
} else{
print("FAIL: Columns do not have the correct specification")
}
}
test_stations_metadata_coltypes(stations_metadata_df) #test, pass
# FOURTH SECTION; testing to see if number of missing values is reasonable or not
test_stations_metadata_nmissing <-
function(df) { # the function with argument df
max_miss_vals <- 200 #max missing values acceptable
if (df %>% map_int( ~ sum(is.na((.)))) %>% sum(.) < max_miss_vals) {
print("PASS: Amount of missing values is reasonable")
} else {
print("FAIL: Too many missing values in data set")
}
} #if the dataframe has a sum of missing values of less than 200, it passes
test_stations_metadata_nmissing(stations_metadata_df)
# FIFTH SECTION - timezone function
test_stations_metadata_latestdata_timezone <-
function(df) {
if (attr(df$latestData,"tzone")=="UTC") { # if df is UTC
print("PASS: latestData has UTC-time zone") #pass
} else { #if not
print("FAIL: latestData does not have expected UTC-time zone") #fail
}
}
test_stations_metadata_latestdata_timezone(stations_metadata_df) # fails
#combing all the functions in a function
test_stations_metadata <-
function(df){
test_stations_metadata_colnames(df)
test_stations_metadata_coltypes(df)
test_stations_metadata_nmissing(df)
test_stations_metadata_nrows(df)
test_stations_metadata_latestdata_timezone(df)
} # nested functions. So when you type the main function, all these functions
# start
test_stations_metadata(stations_metadata_df) # 4 pass, 1 fail
to_iso8601("2016-09-04 10:11:11",-4) #testing
# testing
GQL(
vol_qry(
id=stations_metadata_df$id[1],
from=to_iso8601(stations_metadata_df$latestData[1],-4),
to=to_iso8601(stations_metadata_df$latestData[1],0)
),
.url = configs$vegvesen_url
)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes(latestData) %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes()
stations_metadata_df
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url
stations_metadata_df %>%
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=to)) +
geom_point() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>% GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic()
