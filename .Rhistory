df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
}
setwd("/Users/sjo/Master/BAN400/PART_2/Assignment_7/iterations-sjoojs")
# transform volumes
transform_volumes <- function(json_data) {
# Extract data into a data frame
try({
volumes <- json_data$trafficData$volume$byHour$edges
df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
}
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
# Let's try submitting the query:
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata %>% head()
#### 2: Transforming metadata
source("functions/data_transformations.r")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
#### 3: Testing metadata
source("functions/data_tests.r")
test_stations_metadata(stations_metadata_df)
### 5: Final volume query:
source("gql-queries/vol_qry.r")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic() # Cannot get the graph in the chart, only the frame. Help?
install.packages("glue")
#Problem 2 ----
transform_metadata_to_df <- function(stations_metadata) {
df <- stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, 1, .default=NA_character_)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df)
}
#Problem 4a ----
to_iso8601 <- function(datetime_var, offset_days) {
datetime_var <- as_datetime(datetime_var)
# Add the offset
new_datetime <- datetime_var + days(offset_days)
# Convert to ISO8601 format with a "Z" appended
iso_datetime <- format(new_datetime, format = "%Y-%m-%dT%H:%M:%SZ")
return(iso_datetime)
}
#Test:
to_iso8601(as_datetime("2016-09-01 10:11:12"),0)
to_iso8601(as_datetime("2016-09-01 10:11:12"),-4)
#Function to transform volumes:
transform_volumes <- function(json_data) {
# Extract data into a data frame
try({
volumes <- json_data$trafficData$volume$byHour$edges
df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
}
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
# Let's try submitting the query:
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata %>% head()
#### 2: Transforming metadata
source("functions/data_transformations.r")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
#### 3: Testing metadata
source("functions/data_tests.r")
test_stations_metadata(stations_metadata_df)
### 5: Final volume query:
source("gql-queries/vol_qry.r")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_point() +
theme_classic() # Cannot get the graph in athe chart, only the frame. Help?
install.packages("glue")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
setwd("/Users/sjo/Master/BAN400/PART_2/Assignment_7/iterations-sjoojs")
#Problem 2 ----
transform_metadata_to_df <- function(stations_metadata) {
df <- stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, 1, .default=NA_character_)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df)
}
#Problem 4a ----
to_iso8601 <- function(datetime_var, offset_days) {
datetime_var <- as_datetime(datetime_var)
# Add the offset
new_datetime <- datetime_var + days(offset_days)
# Convert to ISO8601 format with a "Z" appended
iso_datetime <- format(new_datetime, format = "%Y-%m-%dT%H:%M:%SZ")
return(iso_datetime)
}
#Test:
to_iso8601(as_datetime("2016-09-01 10:11:12"),0)
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
#Problem 2 ----
transform_metadata_to_df <- function(stations_metadata) {
df <- stations_metadata[[1]] %>%
map(as_tibble) %>%
list_rbind() %>%
mutate(latestData = map_chr(latestData, 1, .default=NA_character_)) %>%
mutate(latestData = as_datetime(latestData, tz = "UTC")) %>%
unnest_wider(location) %>%
unnest_wider(latLon)
return(df)
}
#Problem 4a ----
to_iso8601 <- function(datetime_var, offset_days) {
datetime_var <- as_datetime(datetime_var)
# Add the offset
new_datetime <- datetime_var + days(offset_days)
# Convert to ISO8601 format with a "Z" appended
iso_datetime <- format(new_datetime, format = "%Y-%m-%dT%H:%M:%SZ")
return(iso_datetime)
}
#Test:
to_iso8601(as_datetime("2016-09-01 10:11:12"),0)
to_iso8601(as_datetime("2016-09-01 10:11:12"),-4)
#Function to transform volumes:
transform_volumes <- function(json_data) {
# Extract data into a data frame
try({
volumes <- json_data$trafficData$volume$byHour$edges
df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
}
# This script contains a function for posting GraphQL-queries.
#
# In order to use the function you must have the following
# packages loaded:
# httr
# jsonlite
GQL <- function(query,
...,
.token = NULL,
.variables = NULL,
.operationName = NULL,
.url = url) {
pbody <-
list(query = query,
variables = .variables,
operationName = .operationName)
if (is.null(.token)) {
res <- POST(.url, body = pbody, encode = "json", ...)
} else {
auth_header <- paste("bearer", .token)
res <-
POST(
.url,
body = pbody,
encode = "json",
add_headers(Authorization = auth_header),
...
)
}
res <- content(res, as = "parsed", encoding = "UTF-8")
if (!is.null(res$errors)) {
warning(toJSON(res$errors))
}
res$data
}
# This file contains tests to be applied to
# the Vegvesen stations-data *after* being transformed
# to a data frame.
#
# All tests are packed in a function test_stations_metadata that apples
# all the aforementioned tests
test_stations_metadata_colnames <-
function(df) {
expected_colnames <- c("id", "name", "latestData", "lat", "lon")
if (all(colnames(df) == expected_colnames) == TRUE) {
print("PASS: Data has the correct columns")
} else{
print("FAIL: Columns do not match the correct specification")
}
} # this function test for expected column names in a dataframe and will return
# "PASS: ..." if the expected column names is the same as in the data frame the function is applied to.
# It will return "FAIL.." indicating that the test has failed and
# the expected column names is not the same as the vector in this function.
test_stations_metadata_nrows <-
function(df) {
min_expected_rows <- 5000
max_expected_rows <- 10000
if (nrow(df) > min_expected_rows & nrow(df) < max_expected_rows) {
print("PASS: Data has a reasonable number of rows")
} else if (nrow(df) <= min_expected_rows) {
print("FAIL: Data has suspiciously few rows")
} else {
print("FAIL: Data has suspiciously many rows")
}
} #This function test for expected number of rows in a dataframe.
# It wil return "PASS:.." if the number of rows in the dataframe is between
# 5000 and 10 000.
#It wil return "Fail:..." if the number of rows are less than 5000 or if
# the number of rows are more than 10 000
test_stations_metadata_coltypes <-
function(df) {
expected_coltypes <-
c("character", "character", "double", "double", "double")
if (all(df %>%
map_chr( ~ typeof(.)) == expected_coltypes) == TRUE) {
print("PASS: All cols have the correct specifications")
} else{
print("FAIL: Columns do not have the correct specification")
}
} #This function test for the expected column types that can be found in a dataframe.
# The specified column types in the vector will be matched with the dataframe.
# If the expected column types is the same as in the dataframe the test will return
# "PASS:..."
# And if the expected column types is different it will return "FAIL:...".
test_stations_metadata_nmissing <-
function(df) {
max_miss_vals <- 200
if (df %>% map_int( ~ sum(is.na((.)))) %>% sum(.) < max_miss_vals) {
print("PASS: Amount of missing values is reasonable")
} else {
print("FAIL: Too many missing values in data set")
}
} #This function is used to test for missing values and will return
# "PASS:..." if missing values is below 200. It will return "FAIL:..." if
# missing values is above 200.
test_stations_metadata_latestdata_timezone <-
function(df) {
if (attr(df$latestData,"tzone")=="UTC") {
print("PASS: latestData has UTC-time zone")
} else {
print("FAIL: latestData does not have expected UTC-time zone")
}
} # This function is used to test if the latestData column has the right time zone
# in this example "UCT". It will return PASS if the time zone is correct and
# FAIL if the time zone is not the same as the expected time zone(UCT)
test_stations_metadata <-
function(df){
test_stations_metadata_colnames(df)
test_stations_metadata_coltypes(df)
test_stations_metadata_nmissing(df)
test_stations_metadata_nrows(df)
test_stations_metadata_latestdata_timezone(df)
}
# This code will use each function and apply it to a dataframe. This is useful
# because we can write one line of code to test all 5 tests at once.
library(httr)
library(jsonlite)
library(ggplot2)
library(DescTools)
library(tidyverse)
library(magrittr)
library(rlang)
library(lubridate)
library(anytime)
library(readr)
library(yaml)
#### 1: Beginning of script
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
# The URL we will use is stored below:
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
# Let's try submitting the query:
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
#### 2: Transforming metadata
source("functions/data_transformations.r")
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
#### 3: Testing metadata
source("functions/data_tests.r")
test_stations_metadata(stations_metadata_df)
### 5: Final volume query:
source("gql-queries/vol_qry.r")
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
install.packages("glue")
# Load function for posting GQL-queries and retrieving data:
source("functions/GQL_function.r")
configs <-
read_yaml("vegvesen_configs.yml")
gql_metadata_qry <- read_file("gql-queries/station_metadata.gql")
stations_metadata <-
GQL(
query=gql_metadata_qry,
.url = configs$vegvesen_url
)
stations_metadata_df <-
stations_metadata %>%
transform_metadata_to_df(.)
test_stations_metadata(stations_metadata_df)
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
stations_metadata_df
transform_volumes
# Extract data into a data frame
try({
volumes <- json_data$trafficData$volume$byHour$edges
df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
#Function to transform volumes:
transform_volumes <- function(json_data) {
# Extract data into a data frame
try({
volumes <- json_data$trafficData$volume$byHour$edges
df <- map_df(volumes, function(x) {
data.frame(
from = x$node$from,
to = x$node$to,
volume = x$node$total$volumeNumbers$volume,
stringsAsFactors = FALSE
)
})
# Convert time variables to datetime
df$from <- lubridate::as_datetime(df$from)
df$to <- lubridate::as_datetime(df$to)
return(df)
}, silent = TRUE)
}
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
) %>%
GQL(., .url = configs$vegvesen_url) %>%
transform_volumes() %>%
ggplot(aes(x=from, y=volume)) +
geom_line() +
theme_classic()
stations_metadata_df %>%
filter(latestData > Sys.Date() - days(7)) %>%
sample_n(1) %$%
vol_qry(
id = id,
from = to_iso8601(latestData, -4),
to = to_iso8601(latestData, 0)
)
